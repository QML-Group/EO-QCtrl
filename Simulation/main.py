import numpy as np 
from qutip import basis, fidelity, identity, sigmax, sigmaz, tensor, destroy
import functions as fc
from qutip.metrics import fidelity
from simulator import QuantumEnvironment
from simulator import GRAPEApproximation
from qrla import QuantumRLAgent
from qrla import GRAPEQRLAgent
from input import *
import matplotlib.pyplot as plt

   
# Initialize Environments
TrainingEnvironment = QuantumEnvironment(number_qubits, h_d, h_c, h_l, t1, t2, target_unitary_cnot, number_of_timesteps, gate_duration, number_of_grape_iterations, n_cycles)
EvaluationEnvironment = QuantumEnvironment(number_qubits, h_d, h_c, h_l, t1, t2, target_unitary_cnot, number_of_timesteps, gate_duration, number_of_grape_iterations, n_cycles)
TrainingEnvironmentGRAPE = GRAPEApproximation(number_qubits, h_d, h_c, h_l, target_unitary_cnot, timesteps = number_of_timesteps, grape_iterations = number_of_grape_iterations)
EvaluationEnvironmentGRAPE = GRAPEApproximation(number_qubits, h_d, h_c, h_l, target_unitary_cnot, timesteps = number_of_timesteps, grape_iterations = number_of_grape_iterations)
ApproximationAgent = GRAPEQRLAgent(TrainingEnvironmentGRAPE, EvaluationEnvironmentGRAPE, num_iterations_Approx, fc_layer_params = (100, 100, 100), replay_buffer_capacity = 100)

# Run GRAPE Approximation Training Phase and save policy
ApproximationAgent.run_training()
ApproximationAgent.save_weights('Test_Policy_Approx')

# Initialize RLAgent Environment including loaded policy
RLAgent = QuantumRLAgent(TrainingEnvironment, EvaluationEnvironment, num_iterations_RL, fc_layer_params = (200, 100, 50, 30, 10), replay_buffer_capacity = 10, policy = 'Test_Policy_Approx', rand_initial_state = False)

# Run Training
RLAgent.run_training()
RLAgent.save_weights('Test_Policy_RL')

# Retrieve highest fidelity pulse
highest_pulse = RLAgent.get_highest_fidelity_pulse()

# Run pulse on Evaluation Environment to cross-check
_, fidelity_rl = EvaluationEnvironment.calculate_fidelity_reward(highest_pulse, plot_result = False)

# Plot the Reward per iteration of the Approximation Agent 
ApproximationAgent.plot_reward_per_iteration()

# Plot Best Pulse Generated by the Approximation agent 
ApproximationAgent.plot_best_pulse()

# Plot the Pulse Generated by the QRLAgent 
RLAgent.plot_final_pulse()

# PLot the Fidelity per iteration of the QRLAgent
RLAgent.plot_fidelity_reward_per_iteration()